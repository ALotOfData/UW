span <- interval(as_date(rowData$datetimeStart), latestCheckinDate)
span <- as.numeric(span, "days")
# unlike the other cases, occurrenceCount should start off equal to the span with the strategy being to remove
# uncessessary days
occurrenceCount <- span
# convert the single event to a dataframe that reps the initial rowData for as many occurrences that happen
output <- rowData %>% slice(rep(1, occurrenceCount))
# update the output df with the correct occurrences and eventDatetimes
for(i in 1:nrow(output)) output$eventDatetime[i] <- as_datetime(output$datetimeStart[i] + days((i-1)*interval))
output$eventDatetime <- as_datetime(output$eventDatetime)
# remove events that are not provided by BYDAY
# create vector of 1-7 vals for days provided by BYDAY
includeDays <- as.vector(strsplit(rowData$byday, ",")[[1]])
includeDays[which(includeDays=="MO")] <- 1
includeDays[which(includeDays=="TU")] <- 2
includeDays[which(includeDays=="WE")] <- 3
includeDays[which(includeDays=="TH")] <- 4
includeDays[which(includeDays=="FR")] <- 5
includeDays[which(includeDays=="SA")] <- 6
includeDays[which(includeDays=="SU")] <- 7
includeDays <- as.integer(includeDays)
output <- output[which(wday(output$eventDatetime, week_start = 1) %in% includeDays),]
# remove events that don't happen on the specified weekly interval by calculating the weeks from the initial
# datetimestart and testing if the week is divisible by the interval
weekIntervals <- as.numeric(interval(as_date(rowData$datetimeStart), output$eventDatetime), "weeks")
# use ceiling such that the 6 days after the datetimestart get rouned to 1 (being the first week) and so on
weekIntervals <- ceiling(weekIntervals)
# test modulus == 0 for weekintervals (these are the events that happen at the specified interval)
weekIntervalPass <- rowData$interval %% weekIntervals
#subset to remove events which don't have a 0 modulo
output <- output[which(weekIntervalPass==0),]
# remove EXDATEs; first convert the comma-separated string to a vector and datetime class
if(is.na(rowData$exdate)==FALSE) {
exdates <- as_datetime(as.vector(strsplit(rowData$exdate, ",")[[1]]))
output <- output[-which(output$eventDatetime %in% exdates),]
}
# assign occurrence
output$occurrence <- seq_along(output$occurrence)
# there may be cases where the exclusions reduce the output to 0 rows so test that before assigning a pass
if(nrow(output)>0) output$processPass <- TRUE
}
# ensure no future events make it through for those that were processed
if(is.na(output$eventDatetime[1])==FALSE) output <- output[which(output$eventDatetime <= latestCheckinDate),]
# remove events that happen after an UNTIL date
if(is.na(rowData$until)==FALSE) output <- output[which(output$eventDatetime < rowData$until),]
output
}
# empty df to hold the results of routineExpander
calendarEventsRaw <- app_routines[FALSE,]
# add the missing columns to make it match output
calendarEventsRaw$eventDatetime <- ymd_hms()
calendarEventsRaw$processPass <- logical()
## Loop which applies routineExpander to app_routines and combines each row's output
for(i in 1:nrow(app_routines)){
processedRowData <- routineExpander(i)
calendarEventsRaw <- bind_rows(calendarEventsRaw,processedRowData)
}
# to avoid needing to rerun the routineExpander, advance to a non-raw name condition
calendarEvents <- calendarEventsRaw
# convert from datetime to date to align with the class needed to join on in app_checkins
calendarEvents$eventDate <- as_date(calendarEvents$eventDatetime)
# pull in the checkin and routine category data, then mutate a checkinFlag
calendarEvents <- left_join(calendarEvents, app_checkins, by = c("eventDate" = "date", "id" = "routineId")) %>%
left_join(app_categories, by = c("categoryId" = "id")) %>%
mutate(checkinFlag = ifelse(is.na(id.y),FALSE,TRUE)) #since id.y is the from app_checkins, is NA if not checked in
## clean the names and columns of the calendarEvents table and add in group_id/group_name
calendarEvents <- calendarEvents %>%
select(routineId = id,
routineName = name.x,
routineClass = type,
routineCat = name.y,
routineSubcat = group,
checkinFlag,
occurrence,
eventDate,
eventDatetime,
userId = userId.x,
locationId,
duration) %>%
left_join(dash_patients[,c(3,4,5)], by = c("userId" = "uuid")) %>%
left_join(dash_groups[,c(3,5,6)], by = c("group_id" = "id"))
# subtset to real patients by removing users in the test groups or with no group
patientCalendarEvents <- calendarEvents[-which(calendarEvents$group_id %in% 1:6 | is.na(calendarEvents$group_id)),]
cleanDataTime <- Sys.time()
##### Summary Results (through this script chunk, there should be no errors and the console should provide this feedback)
totalRuntime <- seconds(round(cleanDataTime - startTime,1))
processingSuccessVolume <- sum(calendarEventsRaw$processPass)
processingFailureVolume <- nrow(calendarEventsRaw[which(calendarEventsRaw$processPass==FALSE),])
daysOfPatientData <- as.numeric(interval(min(patientCalendarEvents$eventDate),max(patientCalendarEvents$eventDate)),"days")
uniquePatientVolume <- length(unique(uusers$user_id))
totalActivitiesVolume <- nrow(patientCalendarEvents)
avgActivitiesPerPatient <- totalActivitiesVolume/uniquePatientVolume
totalCheckinRate <- sum(patientCalendarEvents$checkinFlag)/nrow(patientCalendarEvents)
supportVolume <- nrow(patientCalendarEvents[which(patientCalendarEvents$routineClass=="Support"),])
supportCheckinRate <- nrow(patientCalendarEvents[which(patientCalendarEvents$checkinFlag==TRUE &
patientCalendarEvents$routineClass=="Support"),])/supportVolume
selfcareVolume <- nrow(patientCalendarEvents[which(patientCalendarEvents$routineClass=="SelfCare"),])
selfcareCheckinRate <- nrow(patientCalendarEvents[which(patientCalendarEvents$checkinFlag==TRUE &
patientCalendarEvents$routineClass=="SelfCare"),])/selfcareVolume
percentSupport <- supportVolume/totalActivitiesVolume
percentSelfcare <- selfcareVolume/totalActivitiesVolume
cat(
paste0("Summary Results:", "\n",
"Total runtime: ", totalRuntime, "\n",
"Processing success volume: ", processingSuccessVolume, "\n",
"Processing failure volume: ", processingFailureVolume, "\n",
"Total days of patient data: ", daysOfPatientData, "\n",
"Unique patient volume: ",uniquePatientVolume, "\n",
"Total activities volume: ", totalActivitiesVolume, "\n",
"Average activities per patient: ", avgActivitiesPerPatient, "\n",
"Total check-in rate: ", percent(totalCheckinRate), "\n",
"Support activities volume: ", supportVolume, "\n",
"Support check-in rate: ", percent(supportCheckinRate), "\n",
"Self-care activities volume: ", selfcareVolume, "\n",
"Self-care check-in rate: ", percent(selfcareCheckinRate), "\n",
"Percent Support activities: ", percent(percentSupport), "\n",
"Percent Self-care activities: ", percent(percentSelfcare), "\n"
)
)
latestCheckinDate -7
pastWeekCheckinRate <- nrow(patientCalendarEvents[which(
patientCalendarEvents$eventDate>=latestCheckinDate-7 &
patientCalendarEvents$checkinFlag==TRUE),])/
nrow(patientCalendarEvents[which(
patientCalendarEvents$eventDate>=latestCheckinDate-7),])
pastWeekCheckinRate
########################################################################################################################
# PURPOSE AND README
########################################################################################################################
# PURPOSE: Connect with, clean, and analyze WEconnect V2 data
# NOTES:  Through the cleaning section should be executable all at one time
########################################################################################################################
# VERSION NOTES
########################################################################################################################
# V1: Created the initial data gathering/cleaning resulting in the uusers and patientCalendarEvents dfs
#     Set up basic error reporting
#     Keep in mind there are several areas for improvement including a reduction in the routineExpander redundancy,
#     adding in more cases to handle RRULES not yet encountered.
# V2: Fixed a bug where the interval was lacking for the weekly byday case (it worked before because testing created a
#     global "interval" variable.
#     Fixed a bug with a similar issue as above related to some edits made to eventDate (removed) vs eventDatetime
# V3: Added in check-in rate analysis/plotting
# V4: Added rewards liabilities forecasting and expanded the v1/v2 comparison to include graphs
# V5: Updated section on V1 vs V2 for better comparisons
# V6: Added TODOs for Alex asks on the liabilities forecast
########################################################################################################################
# LOAD PACKAGES, START QA, ENSURE REPRODUCIBILITY, AND SET SAVE
########################################################################################################################
startTime <- Sys.time()
set.seed(1234)
# in case you have data.table, which messes with lubridate
if("data.table" %in% (.packages())) detach("package:data.table", unload=TRUE)
library(dplyr)
library(tidyr)
library(ggplot2)
library(DBI)
library(RPostgres)
library(lubridate)
library(scales)
library(googledrive)
# Windows
# setwd("C:/Users/Will/Google Drive/00-Sync")
########################################################################################################################
# DATABASE CONNECTIONS
########################################################################################################################
## Connect to WEconnect App Follower
pw<-{
"pd6ff229468e2d5df7c1069f01f5f2ce7afd634df27c9765cc17027da9504e1ef"
}
appCon <- dbConnect(RPostgres::Postgres(),
dbname = "deoorcqss2a4da",
host = "ec2-54-161-228-0.compute-1.amazonaws.com",
port = 5432,
user = "u4hecv60jsg8op",
password = pw)
rm(pw) # removes the password
## Connect to WEconnect Dashboard Follower
pw<-{
"p38cd0e2e05764db2f7c9a7008cbe960771007dd4ea0ac2f92c8173a52a930041"
}
dashCon <- dbConnect(RPostgres::Postgres(),
dbname = "d6b9julq6q8gnn",
host = "ec2-18-213-15-93.compute-1.amazonaws.com",
port = 5432,
user = "u1h2je77fbj4ra",
password = pw)
rm(pw) # removes the password
connectTime <- Sys.time()
########################################################################################################################
# GET DATA
########################################################################################################################
## App data
app_categories <- dbGetQuery(appCon,"SELECT * FROM categories")
# app_challenge_completions <- dbGetQuery(appCon,"SELECT * FROM challenge_completions")
# app_checkin_locations <- dbGetQuery(appCon,"SELECT * FROM checkin_locations")
app_checkins <- dbGetQuery(appCon,"SELECT * FROM checkins")
app_genders <- dbGetQuery(appCon,"SELECT * FROM genders")
app_locations <- dbGetQuery(appCon,"SELECT * FROM locations")
# app_migrations <- dbGetQuery(appCon,"SELECT * FROM migrations")
# app_milestones <- dbGetQuery(appCon,"SELECT * FROM milestones")
# app_pg_stat_statements <- dbGetQuery(appCon,"SELECT * FROM pg_stat_statements")
# app_recovery_reasons <- dbGetQuery(appCon,"SELECT * FROM recovery_reasons")
app_routines <- dbGetQuery(appCon,"SELECT * FROM routines")
# app_timed_challenge_start_dates <- dbGetQuery(appCon,"SELECT * FROM timed_challenge_start_dates")
app_user_profiles <- dbGetQuery(appCon,"SELECT * FROM user_profiles")
app_user_profiles_genders <- dbGetQuery(appCon,"SELECT * FROM user_profiles_genders")
# app_user_profiles_recovery_reasons <- dbGetQuery(appCon,"SELECT * FROM user_profiles_recovery_reasons")
app_users <- dbGetQuery(appCon,"SELECT * FROM users")
## Dash data
# dash_access_tokens <- dbGetQuery(dashCon,"SELECT * FROM access_tokens")
dash_groups <- dbGetQuery(dashCon,"SELECT * FROM groups")
# dash_one_time_use_codes <- dbGetQuery(dashCon,"SELECT * FROM one_time_use_codes")
dash_patients <- dbGetQuery(dashCon,"SELECT * FROM patients")
# dash_permissions <- dbGetQuery(dashCon,"SELECT * FROM permissions")
# dash_pg_stat_statements <- dbGetQuery(dashCon,"SELECT * FROM pg_stat_statements")
# dash_risk_level_snapshots <- dbGetQuery(dashCon,"SELECT * FROM risk_level_snapshots")
# dash_role <- dbGetQuery(dashCon,"SELECT * FROM role")
# dash_rolemapping <- dbGetQuery(dashCon,"SELECT * FROM rolemapping")
# dash_transactions <- dbGetQuery(dashCon,"SELECT * FROM transactions")
# dash_users <- dbGetQuery(dashCon,"SELECT * FROM users")
getDataTime <- Sys.time()
########################################################################################################################
# CLEAN DATA
########################################################################################################################
# Clean up data class issues where IDs are improperly text strings in the dashbord database
dash_patients$uuid <- as.integer(dash_patients$uuid)
## Unify the users data into a single table with only the important columns (don't need things like gender priority)
# Build a first name + last initial column, reorder, and rename
uusers <- left_join(app_users, app_user_profiles, by = c("id" = "userId")) %>%
left_join(app_user_profiles_genders, by = c("id" = "userProfilesId")) %>%
left_join(app_genders, by = c("gendersId" = "id")) %>%
left_join(dash_patients, by = c("id" = "uuid")) %>%
left_join(dash_groups, by = c("group_id" = "id")) %>%
mutate(firstName_lastInitial = paste0(firstName, " ", gsub("[^A-Z]*([A-Z])[^A-Z]*", "\\1", lastName),".")) %>%
select(c("id",
"firstName_lastInitial",
"firstName",
"lastName",
"email",
"birthDate",
"recoveryDate",
"timeZone",
"name.x",
"parent_id",
"group_id",
"group_code")) %>%
rename(user_id = id, gender = name.x)
## Exclude groups 1:6, which are test groups, and users with NA groups (also testers)
uusers <- uusers[-which(uusers$group_id %in% 1:6 | is.na(uusers$group_id)),]
### Build parser for recurring routines
# notes on RRULE (RFC 5455) for app_routines$recurrance
# https://www.kanzaki.com/docs/ical/rrule.html
# There are no R packages to do the parsing so I'll do my best to write a parser
## Create columns for all RRULE parameters by parsing the recurrence column
app_routines$recurring <- NA # a TRUE or FALSE field
app_routines$freq <- NA
app_routines$interval <- as.integer(NA)
app_routines$until <- as_datetime(NA)
app_routines$exdate <- NA
app_routines$byday <- NA
app_routines$datetimeStart <- as_datetime(NA)
app_routines$occurrence <- NA # will hold values specifying if its the first, second, etc. in a routine
# Set recurring equal to TRUE unless the recurrence has 'RDATE' (the flag for a single event)
app_routines$recurring <- TRUE
app_routines$recurring[grepl("^.RDATE.*",app_routines$recurrence)] <- FALSE
# parse the other fields
app_routines$freq[grepl(".*FREQ=.*",app_routines$recurrence)] <-
gsub(".*FREQ=(.*?);.*",
"\\1",
app_routines$recurrence[grepl(".*FREQ=.*",app_routines$recurrence)],
perl = TRUE)
app_routines$interval[grepl(".*INTERVAL=.*",app_routines$recurrence)] <-
gsub(".*INTERVAL=(\\d+).*",
"\\1",
app_routines$recurrence[grepl(".*INTERVAL=.*",app_routines$recurrence)],
perl = TRUE)
app_routines$interval <- as.integer(app_routines$interval)
app_routines$until[grepl(".*UNTIL=.*",app_routines$recurrence)] <-
ymd_hms(gsub(".*UNTIL=(.{15}).*", #this leaves off the trailing Z--unsure if needed atm
"\\1",
app_routines$recurrence[grepl(".*UNTIL=.*",app_routines$recurrence)],
perl = TRUE))
# exdate can be multiple dates so we'll store as a comma separated string for now
app_routines$exdate[grepl(".*EXDATE.*",app_routines$recurrence)] <-
gsub(".*EXDATE;.*?(\\d.*?)[\"}].*",
"\\1",
app_routines$recurrence[grepl(".*EXDATE.*",app_routines$recurrence)],
perl = TRUE)
app_routines$byday[grepl(".*BYDAY=.*",app_routines$recurrence)] <-
gsub(".*BYDAY=(.*?);.*",
"\\1",
app_routines$recurrence[grepl(".*BYDAY=.*",app_routines$recurrence)],
perl = TRUE)
app_routines$datetimeStart <-
ymd_hms(gsub(".*?([0-9]{8}T[0-9]{6}).*",
"\\1",
app_routines$recurrence,
perl = TRUE))
# This will be limited to the day before the latest check-in (ensuring a complete day)
latestCheckinDate <- as_date(max(app_checkins$date))
# remove routines which were scheduled on the date of the latest check-in
app_routines <- app_routines[-which(app_routines$datetimeStart>=latestCheckinDate),]
## Function which takes an app_routines row as input, uses its parameters, and creates one-row-per-event with correct
# dates given the parameters
routineExpander <- function(row_input) {
# subset to row for processing
rowData <- app_routines[row_input,]
rowData$eventDatetime <- as_datetime(NA)
# flag to see which rows aren't being processed
rowData$processPass <- FALSE
output <- rowData
# case for non-recurring
if(rowData$recurring==FALSE) {
rowData$occurrence <- 1
rowData$eventDatetime <- rowData$datetimeStart
output <- rowData
# there may be cases where the exclusions reduce the output to 0 rows so test that before assigning a pass
if(nrow(output)>0) output$processPass <- TRUE
}
# case for daily occurrences with variable intervals and exdate(s)
if(rowData$recurring==TRUE & rowData$freq=="DAILY" & is.na(rowData$interval)==FALSE) {
interval <- rowData$interval
span <- interval(as_date(rowData$datetimeStart), latestCheckinDate)
span <- as.numeric(span, "days")
# convert span to occurrences by dividing by the interval (will be equal if interval is 1).  Use floor to rounddown
occurrenceCount <- floor(span/rowData$interval)
# convert the single event to a dataframe that reps the initial rowData for as many occurrences that happen
output <- rowData %>% slice(rep(1, occurrenceCount))
# update the output df with the correct occurrences and eventDatetimes
for(i in 1:nrow(output)) output$eventDatetime[i] <- as_datetime(output$datetimeStart[i] + days((i-1)*interval))
output$eventDatetime <- as_datetime(output$eventDatetime)
# remove EXDATEs; first convert the comma-separated string to a vector and datetime class
if(is.na(rowData$exdate)==FALSE) {
exdates <- as_datetime(as.vector(strsplit(rowData$exdate, ",")[[1]]))
output <- output[-which(output$eventDatetime %in% exdates),]
}
# assign occurrence
output$occurrence <- seq_along(output$occurrence)
# there may be cases where the exclusions reduce the output to 0 rows so test that before assigning a pass
if(nrow(output)>0) output$processPass <- TRUE
}
# case for weekly occurrences with variable intervals and exdate(s)
if(rowData$recurring==TRUE & rowData$freq=="WEEKLY" & is.na(rowData$interval)==FALSE & is.na(rowData$byday)==TRUE) {
interval <- rowData$interval
span <- interval(as_date(rowData$datetimeStart), latestCheckinDate)
span <- as.numeric(span, "days")
# convert span to occurrences by dividing by the interval (will be equal if interval is 1).  Use floor to rounddown
occurrenceCount <- floor(span/interval/7)+1 #7 for days in the week; +1 to ensure BYDAY partial weeks make it in
# convert the single event to a dataframe that reps the initial rowData for as many occurrences that happen
output <- rowData %>% slice(rep(1, occurrenceCount))
# update the output df with the correct occurrences and eventDatetimes
for(i in 1:nrow(output)) output$eventDatetime[i] <- as_datetime(output$datetimeStart[i] + weeks((i-1)*interval))
output$eventDatetime <- as_datetime(output$eventDatetime)
# remove EXDATEs; first convert the comma-separated string to a vector and datetime class
if(is.na(rowData$exdate)==FALSE) {
exdates <- as_datetime(as.vector(strsplit(rowData$exdate, ",")[[1]]))
output <- output[-which(output$eventDatetime %in% exdates),]
}
# assign occurrence
output$occurrence <- seq_along(output$occurrence)
# there may be cases where the exclusions reduce the output to 0 rows so test that before assigning a pass
if(nrow(output)>0) output$processPass <- TRUE
}
# case for WEEKLY BYDAY
# general strategy here is to create events for all days, then subset down to the days provided
if(rowData$recurring==TRUE & rowData$freq=="WEEKLY" & is.na(rowData$interval)==FALSE & is.na(rowData$byday)==FALSE) {
interval <- rowData$interval
span <- interval(as_date(rowData$datetimeStart), latestCheckinDate)
span <- as.numeric(span, "days")
# unlike the other cases, occurrenceCount should start off equal to the span with the strategy being to remove
# uncessessary days
occurrenceCount <- span
# convert the single event to a dataframe that reps the initial rowData for as many occurrences that happen
output <- rowData %>% slice(rep(1, occurrenceCount))
# update the output df with the correct occurrences and eventDatetimes
for(i in 1:nrow(output)) output$eventDatetime[i] <- as_datetime(output$datetimeStart[i] + days((i-1)*interval))
output$eventDatetime <- as_datetime(output$eventDatetime)
# remove events that are not provided by BYDAY
# create vector of 1-7 vals for days provided by BYDAY
includeDays <- as.vector(strsplit(rowData$byday, ",")[[1]])
includeDays[which(includeDays=="MO")] <- 1
includeDays[which(includeDays=="TU")] <- 2
includeDays[which(includeDays=="WE")] <- 3
includeDays[which(includeDays=="TH")] <- 4
includeDays[which(includeDays=="FR")] <- 5
includeDays[which(includeDays=="SA")] <- 6
includeDays[which(includeDays=="SU")] <- 7
includeDays <- as.integer(includeDays)
output <- output[which(wday(output$eventDatetime, week_start = 1) %in% includeDays),]
# remove events that don't happen on the specified weekly interval by calculating the weeks from the initial
# datetimestart and testing if the week is divisible by the interval
weekIntervals <- as.numeric(interval(as_date(rowData$datetimeStart), output$eventDatetime), "weeks")
# use ceiling such that the 6 days after the datetimestart get rouned to 1 (being the first week) and so on
weekIntervals <- ceiling(weekIntervals)
# test modulus == 0 for weekintervals (these are the events that happen at the specified interval)
weekIntervalPass <- rowData$interval %% weekIntervals
#subset to remove events which don't have a 0 modulo
output <- output[which(weekIntervalPass==0),]
# remove EXDATEs; first convert the comma-separated string to a vector and datetime class
if(is.na(rowData$exdate)==FALSE) {
exdates <- as_datetime(as.vector(strsplit(rowData$exdate, ",")[[1]]))
output <- output[-which(output$eventDatetime %in% exdates),]
}
# assign occurrence
output$occurrence <- seq_along(output$occurrence)
# there may be cases where the exclusions reduce the output to 0 rows so test that before assigning a pass
if(nrow(output)>0) output$processPass <- TRUE
}
# ensure no future events make it through for those that were processed
if(is.na(output$eventDatetime[1])==FALSE) output <- output[which(output$eventDatetime <= latestCheckinDate),]
# remove events that happen after an UNTIL date
if(is.na(rowData$until)==FALSE) output <- output[which(output$eventDatetime < rowData$until),]
output
}
# empty df to hold the results of routineExpander
calendarEventsRaw <- app_routines[FALSE,]
# add the missing columns to make it match output
calendarEventsRaw$eventDatetime <- ymd_hms()
calendarEventsRaw$processPass <- logical()
## Loop which applies routineExpander to app_routines and combines each row's output
for(i in 1:nrow(app_routines)){
processedRowData <- routineExpander(i)
calendarEventsRaw <- bind_rows(calendarEventsRaw,processedRowData)
}
# to avoid needing to rerun the routineExpander, advance to a non-raw name condition
calendarEvents <- calendarEventsRaw
# convert from datetime to date to align with the class needed to join on in app_checkins
calendarEvents$eventDate <- as_date(calendarEvents$eventDatetime)
# pull in the checkin and routine category data, then mutate a checkinFlag
calendarEvents <- left_join(calendarEvents, app_checkins, by = c("eventDate" = "date", "id" = "routineId")) %>%
left_join(app_categories, by = c("categoryId" = "id")) %>%
mutate(checkinFlag = ifelse(is.na(id.y),FALSE,TRUE)) #since id.y is the from app_checkins, is NA if not checked in
## clean the names and columns of the calendarEvents table and add in group_id/group_name
calendarEvents <- calendarEvents %>%
select(routineId = id,
routineName = name.x,
routineClass = type,
routineCat = name.y,
routineSubcat = group,
checkinFlag,
occurrence,
eventDate,
eventDatetime,
userId = userId.x,
locationId,
duration) %>%
left_join(dash_patients[,c(3,4,5)], by = c("userId" = "uuid")) %>%
left_join(dash_groups[,c(3,5,6)], by = c("group_id" = "id"))
# subtset to real patients by removing users in the test groups or with no group
patientCalendarEvents <- calendarEvents[-which(calendarEvents$group_id %in% 1:6 | is.na(calendarEvents$group_id)),]
cleanDataTime <- Sys.time()
##### Summary Results (through this script chunk, there should be no errors and the console should provide this feedback)
totalRuntime <- seconds(round(cleanDataTime - startTime,1))
processingSuccessVolume <- sum(calendarEventsRaw$processPass)
processingFailureVolume <- nrow(calendarEventsRaw[which(calendarEventsRaw$processPass==FALSE),])
daysOfPatientData <- as.numeric(interval(min(patientCalendarEvents$eventDate),max(patientCalendarEvents$eventDate)),"days")
uniquePatientVolume <- length(unique(uusers$user_id))
totalActivitiesVolume <- nrow(patientCalendarEvents)
avgActivitiesPerPatient <- totalActivitiesVolume/uniquePatientVolume
totalCheckinRate <- sum(patientCalendarEvents$checkinFlag)/nrow(patientCalendarEvents)
supportVolume <- nrow(patientCalendarEvents[which(patientCalendarEvents$routineClass=="Support"),])
supportCheckinRate <- nrow(patientCalendarEvents[which(patientCalendarEvents$checkinFlag==TRUE &
patientCalendarEvents$routineClass=="Support"),])/supportVolume
selfcareVolume <- nrow(patientCalendarEvents[which(patientCalendarEvents$routineClass=="SelfCare"),])
selfcareCheckinRate <- nrow(patientCalendarEvents[which(patientCalendarEvents$checkinFlag==TRUE &
patientCalendarEvents$routineClass=="SelfCare"),])/selfcareVolume
percentSupport <- supportVolume/totalActivitiesVolume
percentSelfcare <- selfcareVolume/totalActivitiesVolume
pastWeekCheckinRate <- nrow(patientCalendarEvents[which(
patientCalendarEvents$eventDate>=latestCheckinDate-7 &
patientCalendarEvents$checkinFlag==TRUE),])/
nrow(patientCalendarEvents[which(
patientCalendarEvents$eventDate>=latestCheckinDate-7),])
cat(
paste0("Summary Results:", "\n",
"Total runtime: ", totalRuntime, "\n",
"Processing success volume: ", processingSuccessVolume, "\n",
"Processing failure volume: ", processingFailureVolume, "\n",
"Total days of patient data: ", daysOfPatientData, "\n",
"Unique patient volume: ",uniquePatientVolume, "\n",
"Total activities volume: ", totalActivitiesVolume, "\n",
"Average activities per patient: ", avgActivitiesPerPatient, "\n",
"Total check-in rate: ", percent(totalCheckinRate), "\n",
"Support activities volume: ", supportVolume, "\n",
"Support check-in rate: ", percent(supportCheckinRate), "\n",
"Self-care activities volume: ", selfcareVolume, "\n",
"Self-care check-in rate: ", percent(selfcareCheckinRate), "\n",
"Percent Support activities: ", percent(percentSupport), "\n",
"Percent Self-care activities: ", percent(percentSelfcare), "\n",
"Past week total check-in rate", percent(pastWeekCheckinRate), "\n"
)
)
# protip: ctrl+alt+b to run to here with cursor here
app_timed_challenge_start_dates <- dbGetQuery(appCon,"SELECT * FROM timed_challenge_start_dates")
app_challenge_completions <- dbGetQuery(appCon,"SELECT * FROM challenge_completions")
app_milestones <- dbGetQuery(appCon,"SELECT * FROM milestones")
dash_one_time_use_codes <- dbGetQuery(dashCon,"SELECT * FROM one_time_use_codes")
# Use the whiteboard_maxPotentialLiabilities (pic of whiteboard brainstorm) to see the thought process
# general idea is that we build two reference tables (one for challenges and the other for milestones).  Then, using
# that plus the app_challenge_completions, we build an all-up view of each user's potential per day, then summarize
# into another table (grouping on date) to get the max expected liability per day
## Build challenge table
challengeRef <- data.frame("challengeId" = 1:22,
"maxRewardAmt" = c(rep(10,7), rep(15,3), rep(20,3), rep(25,4), rep(30,5)),
"challengeLength" = c(NA,NA,NA,3,4,5,6,7,8,9,11,13,15,17,19,21,24,27,30,33,36,39),
"timerDays" = c(NA,NA,NA,1,4,9,15,22,30,39,50,63,78,95,114,135,159,186,216,249,285,324))
## Build milestone table
milestoneRef <- data.frame("milestoneId" = 1:6,
"maxMilestoneAmt" = c(rep(50,4),75,100),
"timerDays" = c(30,60,90,183,274,365))
View(milestoneRef)
View(challengeRef)
